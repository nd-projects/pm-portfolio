---
title: 'ADAS Test Simulator: Building the Product Roadmap'
description: 'How I led product development for a simulation platform that achieved 85% safety coverage with sub-second CI/CD performance, transforming how BMW engineers test autonomous driving systems.'
status: 'draft'
category: 'Product Development'
technologies: ['C++', 'Unity', 'CI/CD', 'Bazel']
timeline: '18 months'
team_size: '12 engineers'
metrics:
  - label: 'Safety Coverage Achieved'
    value: '85%'
    description: 'Critical test scenarios covered'
  - label: 'CI/CD Performance'
    value: 'Under 1s'
    description: 'Scenario execution time'
  - label: 'Engineer Adoption'
    value: '95%'
    description: 'Team workflow integration'
  - label: 'Automated Scenarios'
    value: '45'
    description: 'Critical test cases built'
---

## The Challenge: Understanding User Needs in Safety-Critical Testing

BMW's autonomous driving program faced a critical bottleneck: **how do you test safety-critical systems without endangering lives?**

As Product Owner, I needed to understand not just the technical challenge, but how engineers actually worked with testing tools daily.

### User Research: The Engineer's Dilemma

Through extensive interviews with BMW's safety engineering team, I discovered the real pain points:

**Current Testing Workflow Problems:**

- **Time-intensive feedback loops**: 2-3 hours to validate single feature changes
- **Limited scenario coverage**: Only 20-30 edge cases testable safely in physical tests
- **Non-reproducible results**: Weather, traffic, and human factors introduced variability
- **Integration friction**: Testing happened in isolation from development workflow
- **Cost barriers**: $50K+ per test vehicle setup limited experimentation

**Engineer Quotes from Discovery:**

> "We spend more time setting up tests than analyzing results" - Senior Safety Engineer
>
> "I can't iterate quickly when each test cycle takes half a day" - ADAS Developer
>
> "We need testing that integrates with our existing CI/CD, not replaces it" - DevOps Lead

## Discovery: The 45 Critical Scenarios Framework

Working closely with BMW's safety team, I led a comprehensive analysis to identify what engineers actually needed to test:

### Critical Safety Scenarios Analysis

**High-Frequency, High-Risk Scenarios:**

- **Highway merging** in dense traffic conditions
- **Pedestrian detection** in low-visibility situations
- **Emergency braking** with multiple vehicle interactions
- **Weather-related** sensor degradation scenarios
- **Construction zone** navigation challenges

### Product Requirements Definition

From user research, I defined three core product pillars:

#### 1. Coverage Completeness

- **Target**: 85% coverage across all critical scenarios (regulatory requirement)
- **User need**: Confidence that edge cases are tested
- **Success metric**: Reduction in production safety incidents

#### 2. CI/CD Performance

- **Target**: Sub-second scenario execution
- **User need**: Fast feedback loops for iterative development
- **Success metric**: Developer workflow adoption rates

#### 3. Usability Integration

- **Target**: Seamless integration with existing tools
- **User need**: Minimal workflow disruption
- **Success metric**: Engineer adoption and daily usage

## Solution Architecture: Performance-First Design

### Core Design Philosophy

Built on the principle that **speed enables better testing practices**:

```python
# Core simulation framework designed for speed
class FastScenario:
    def __init__(self, scenario_config):
        # Pre-computed scenario data for speed
        self.scenario_cache = precompute_scenario_data(scenario_config)
        self.expected_behaviors = load_safety_requirements()

    def execute_fast(self, adas_system):
        # Optimized for CI/CD: under 1s execution target
        start_time = time.time()
        result = validate_cached_response(
            adas_system.process(self.scenario_cache)
        )
        execution_time = time.time() - start_time
        assert execution_time < 1.0  # Performance requirement
        return result
```

### Key Technical Innovations for Performance

#### 1. Scenario Pre-computation Engine

- **Ahead-of-time scenario generation** eliminates runtime computation
- **Cached scenario states** for instant test execution
- **Parallel scenario processing** across multiple CPU cores
- **Memory-mapped scenario data** for fastest possible access

#### 2. CI/CD Optimized Architecture

- **Lightweight test runners** that integrate with existing build systems
- **Incremental testing** - only run scenarios affected by code changes
- **Distributed execution** across build farm infrastructure
- **Real-time result streaming** for immediate developer feedback

#### 3. Unity-Based Visualization (On-Demand)

- **Headless execution** for CI/CD performance
- **On-demand 3D rendering** for engineering review
- **Multi-perspective recording** only when needed for debugging
- **Sensor simulation** with configurable fidelity levels

## Implementation Roadmap: User-Driven Delivery

### Phase 1: Core Performance Foundation (Months 1-6)

**Objective**: Prove sub-second execution is possible

- **10 high-priority scenarios** based on user interviews
- **Basic CI/CD integration** with BMW's existing Jenkins pipeline
- **Performance baseline**: Target under 1s per scenario
- **Single platform support**: BMW X5 (most-used development vehicle)

**Key Deliverables:**

- Proof-of-concept with performance metrics
- Jenkins plugin for automated execution
- Basic pass/fail reporting dashboard

### Phase 2: Scale and Usability (Months 7-12)

**Objective**: Achieve full scenario coverage with excellent UX

- **45 critical scenarios** fully automated
- **Advanced CI/CD features**: parallel execution, smart retries
- **Developer UX improvements**: local testing, VS Code integration
- **Multi-platform support**: Entire BMW vehicle lineup

**Key Deliverables:**

- Complete scenario library
- Developer tools and IDE integration
- Performance optimization (average 0.7s per scenario)
- Self-service scenario creation tools

### Phase 3: Production Excellence (Months 13-18)

**Objective**: 100% team adoption and regulatory readiness

- **Advanced analytics**: Test trend analysis, failure prediction
- **Regulatory integration**: Automated report generation
- **Performance optimization**: Target 0.5s average execution
- **Enterprise features**: Role-based access, audit trails

**Key Deliverables:**

- Production-ready monitoring and alerting
- Regulatory compliance reporting
- Advanced performance features
- Complete documentation and training materials

## UX Design: Making Complexity Simple

### Developer Experience Priorities

#### 1. Workflow Integration

**Problem**: Engineers resist tools that disrupt their existing workflow
**Solution**: Build testing into existing development tools

- **VS Code extension** for local scenario testing
- **Git hooks** for automatic test execution on commits
- **Slack integration** for test result notifications
- **Jira integration** for automatic issue creation on failures

#### 2. Immediate Feedback

**Problem**: Long feedback loops slow down development
**Solution**: Real-time testing with instant results

- **Live test execution** as code is written
- **Progressive result streaming** - see results as tests complete
- **Smart notifications** - only alert on regressions or new failures
- **Visual diff tools** for scenario comparison

#### 3. Self-Service Capability

**Problem**: Engineers dependent on specialists for test creation
**Solution**: Democratize scenario creation

```yaml
# Simple YAML interface for scenario creation
scenario:
  name: 'Highway Merge Dense Traffic'
  type: 'merge'
  traffic_density: 'high'
  weather: 'clear'
  expected_outcome: 'safe_merge'
  performance_target: '< 0.8s'
```

## Results: Transforming Engineering Culture

### Coverage Achievement

- **85% safety coverage** across all critical scenarios
- **200+ edge cases** discovered that physical testing missed
- **Zero safety-critical bugs** reached production during 18-month period
- **Regulatory approval** accelerated by 8 months

### Performance Excellence

- **Average execution time**: 0.6 seconds per scenario
- **CI/CD integration**: 95% of commits automatically tested
- **Parallel execution**: 45 scenarios completed in under 30 seconds
- **99.9% uptime** in CI/CD environment

### Usability Success

- **95% engineer adoption** within 6 months
- **Daily active usage**: 85% of development team
- **Self-service scenarios**: 40% of new tests created by engineers
- **Support ticket reduction**: 70% decrease in testing-related issues

### Technical Impact

- **240M virtual kilometers** simulated (equivalent to 500 years of driving)
- **99.9% accuracy** validated against physical test data
- **Cross-platform compatibility** across BMW's entire vehicle lineup
- **Zero performance regressions** in production deployment

## Product Management Lessons

### 1. Performance Drives Adoption

The sub-second execution requirement wasn't just technical—it was the key to changing engineer behavior and achieving high adoption rates.

### 2. UX in Technical Tools Matters

Even highly technical users need intuitive interfaces. The best testing framework is useless if engineers won't use it daily.

### 3. Iterative User Feedback

Regular check-ins with engineering teams revealed usability issues early, preventing costly architectural changes later.

### 4. Regulatory Constraints as Product Features

Safety requirements weren't limitations—they became differentiating product features that added business value.

---

**Next**: Read about how this internal success became an [open-source industry standard →](./adas-simulator-opensource)

**Technologies**: Python, C++, Unity, CI/CD, Jenkins, VS Code Extensions  
**Timeline**: 18 months from concept to full production adoption  
**Team**: 12 engineers, 3 UX researchers, 2 DevOps specialists, PM lead
